{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### step 1: make list of elements of file\n",
    "\n",
    "        list_img = os.listdir(file_addr)\n",
    "\n",
    "### step 2: resize all images from input folder and store in input_resize folder\n",
    "\n",
    "        for i in list_img:\n",
    "            im = Image.open(input_file_addr+'\\\\'+i)\n",
    "            im1 = im.resize((200,200))\n",
    "            im2 = im1.convert('RGB')\n",
    "            im2.save(input_resize_file_addr+'\\\\'+i,'JPEG')   \n",
    "    \n",
    "### step 3: flatten images to matrix(m,n_x)\n",
    "\n",
    "        X = np.array([np.array(Image.open(input_file_addr+'\\\\'+i)).flatten() for i in list_img],'f')\n",
    "        X = X.T\n",
    "\n",
    "### step 4: labelling the dataset\n",
    "\n",
    "        m = X.shape[1]           #no. of images\n",
    "        m_t = X_t.shape[1]\n",
    "        Y = np.zeros((m,1),dtype=int)\n",
    "        Y_t = np.zeros((m_t,1),dtype=int)\n",
    "        Y[0:m] = 1 \n",
    "\n",
    "### step 5: reshape Y to maintain the consistency\n",
    "\n",
    "        Y = Y.reshape((1,X.shape[1])).T\n",
    "\n",
    "### step 6: shuffle data (need to do it for better result)\n",
    "\n",
    "        X_train,Y_train = shuffle(X,Y, random_state=0)\n",
    "\n",
    "### step 7: standardize the data (not neccessary but good practice)\n",
    "\n",
    "        X_train = X_train/255   #255 is maximum possible value in image pixle \n",
    "\n",
    "### step 8: do all above steps for test data\n",
    "\n",
    "        X_test = ....\n",
    "        Y_test = ....\n",
    "\n",
    "### step 9: run the model function\n",
    "\n",
    "        n_h1 = 7      #number of nodes in layer\n",
    "        d = model(X_train, Y_train, X_test, Y_test,n_h1, num_iterations = 6000, learning_rate = 0.05,lambd = 0)\n",
    "\n",
    "### step 10: Print train/test Errors\n",
    "\n",
    "        Y_prediction_train = d[\"Y_prediction_train\"]\n",
    "        Y_prediction_test = d[\"Y_prediction_test\"]\n",
    "\n",
    "        print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "        print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "### step 11:draw cost vs iteration graph\n",
    "    \n",
    "        plot_cost(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid function\n",
    "def sigmoid(z):\n",
    "    s = 1/(1+np.exp(-z))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialization of parameter w,b\n",
    "def initialize(n_x):\n",
    "    W = np.random.randn(1,n_x)*0.01\n",
    "    #W = np.zeros(shape=(1,n_x))\n",
    "    b = 0\n",
    "    assert(W.shape == (1,n_x))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "\n",
    "    return W,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#forword and backword propagation\n",
    "def propagate(X,Y,W,b):\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    #forword propagation\n",
    "    Z = np.dot(W,X) + b\n",
    "    A = sigmoid(Z)\n",
    "    J = (-1/m)* np.sum(Y * np.log1p(A) + (1-Y) * (np.log1p(1-A)))\n",
    "    \n",
    "    #backword propagation\n",
    "    dZ = A - Y\n",
    "    dW = (1/m)*np.dot(dZ,X.T)\n",
    "    db = (1/m)*np.sum(dZ)\n",
    "    \n",
    "    assert(dW.shape == W.shape)\n",
    "    assert(db.dtype == float)\n",
    "    J = np.squeeze(J)\n",
    "    assert(J.shape == ())\n",
    "    \n",
    "    grad = {\"dW\":dW,\n",
    "            \"db\":db}\n",
    "    \n",
    "    return grad,J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(W, b, X, Y, num_iterations, learning_rate):\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grad,J = propagate(X,Y,W,b)\n",
    "    \n",
    "        dW = grad[\"dW\"]\n",
    "        db = grad[\"db\"]\n",
    "        \n",
    "        W = W - learning_rate*dW\n",
    "        b = b - learning_rate*db\n",
    "        \n",
    "        if i%100==0:\n",
    "            costs.append(J)\n",
    "            print (\"Cost after iteration %i: %f\" % (i, J))\n",
    "        \n",
    "    params = {\"W\": W,\n",
    "              \"b\": b}\n",
    "    grad = {\"dW\": dW,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grad, costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict function\n",
    "def predict(W,b,X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    W = W.reshape(1,X.shape[0])\n",
    "    Z = np.dot(W, X) + b\n",
    "    A = sigmoid(Z)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "       \n",
    "    assert(Y_prediction.shape == (1, m))\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2000, learning_rate=0.5):\n",
    "    \n",
    "    # initialize parameters with zeros\n",
    "    W, b = initialize(X_train.shape[0])\n",
    "\n",
    "    # Gradient descent\n",
    "    parameters, grads, costs = optimize(W, b, X_train, Y_train, num_iterations, learning_rate)\n",
    "    \n",
    "    # Retrieve parameters w and b from dictionary \"parameters\"\n",
    "    W = parameters[\"W\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Predict test/train set examples\n",
    "    Y_prediction_test = predict(W, b, X_test)\n",
    "    Y_prediction_train = predict(W, b, X_train)\n",
    "\n",
    "    # Print train/test Errors\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    \n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test, \n",
    "         \"Y_prediction_train\" : Y_prediction_train, \n",
    "         \"W\" : W, \n",
    "         \"b\" : b,\n",
    "         \"learning_rate\" : learning_rate,\n",
    "         \"num_iterations\": num_iterations}\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = model(X_train, Y_train, X_test, Y_test, num_iterations = 5000, learning_rate = 0.0002)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost(costs):\n",
    "    # plot the cost\n",
    "    plt.plot(np.squeeze(costs))\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per tens)')\n",
    "    plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
